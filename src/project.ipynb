{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:16.467474Z",
     "start_time": "2024-12-04T03:15:16.464857Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from twisted.conch.scripts.tkconch import frame\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import ssl\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99cb3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving an SSLCertVerificationError when trying to fetch UCI repo\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185308e5",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "For milestone 2, we are completing all data preprocessing operations including fetching the data, dropping unnecessary columns, encoding categorical data and normalizing continous columns. Finally, we will be splitting the data into train, test and validation sets using a 80/20 split between test and training data, and 80/20 split between split training data and a validation set (because the data set is so large we can afford to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "797b9a8dc486d133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.353072Z",
     "start_time": "2024-12-04T03:15:16.477593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop missing values:  (48842, 14)\n",
      "after drop missing values:  (47621, 14)\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "features = pd.DataFrame(adult.data.features)\n",
    "target = pd.DataFrame(adult.data.targets)\n",
    "\n",
    "\n",
    "#drop the education column as it is already represented in the education_num column\n",
    "features = features.drop(columns=['education'])\n",
    "data = pd.concat([features, target], axis=1)\n",
    "\n",
    "print(\"before drop missing values: \", data.shape)\n",
    "# drop missing values\n",
    "data = data.dropna()\n",
    "\n",
    "print(\"after drop missing values: \", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95b7681869b288be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.386132Z",
     "start_time": "2024-12-04T03:15:19.372890Z"
    }
   },
   "outputs": [],
   "source": [
    "before = {'workclass': data['workclass'].unique(),\n",
    "          'marital-status': data['marital-status'].unique(),\n",
    "          'occupation': data['occupation'].unique(),\n",
    "          'relationship': data['relationship'].unique(),\n",
    "          'race': data['race'].unique(),\n",
    "          'native-country': data['native-country'].unique(),\n",
    "          'income': data['income'].unique()\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cdcb59f2bfb6b3",
   "metadata": {},
   "source": [
    "## Categorical Data Preprocessing\n",
    "using LabelEncoder to convert categorical data to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d3ed6bd5c223b39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.459249Z",
     "start_time": "2024-12-04T03:15:19.429402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education-num  marital-status  occupation  \\\n",
       "0   39          7   77516             13               4           1   \n",
       "1   50          6   83311             13               2           4   \n",
       "2   38          4  215646              9               0           6   \n",
       "3   53          4  234721              7               2           6   \n",
       "4   28          4  338409             13               2          10   \n",
       "\n",
       "   relationship  race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0             1     4    Male          2174             0              40   \n",
       "1             0     4    Male             0             0              13   \n",
       "2             1     4    Male             0             0              40   \n",
       "3             0     2    Male             0             0              40   \n",
       "4             5     2  Female             0             0              40   \n",
       "\n",
       "   native-country income  \n",
       "0              39  <=50K  \n",
       "1              39  <=50K  \n",
       "2              39  <=50K  \n",
       "3              39  <=50K  \n",
       "4               5  <=50K  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_colname = ['workclass', 'marital-status', 'occupation', 'relationship', 'native-country','race']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "for i in cate_colname:\n",
    "    data[i] = labelEncoder.fit_transform(data[i])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9291018eb0da06f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.500987Z",
     "start_time": "2024-12-04T03:15:19.495229Z"
    }
   },
   "outputs": [],
   "source": [
    "after = {'workclass': data['workclass'].unique(),\n",
    "          'marital-status': data['marital-status'].unique(),\n",
    "          'occupation': data['occupation'].unique(),\n",
    "          'relationship': data['relationship'].unique(),\n",
    "          'race': data['race'].unique(),\n",
    "          'native-country': data['native-country'].unique(),\n",
    "          'income': data['income'].unique()\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5df4b409366b454f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.529682Z",
     "start_time": "2024-12-04T03:15:19.526619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: workclass before: 9 after: 9\n",
      "col_name: marital-status before: 7 after: 7\n",
      "col_name: occupation before: 15 after: 15\n",
      "col_name: relationship before: 6 after: 6\n",
      "col_name: race before: 5 after: 5\n",
      "col_name: native-country before: 42 after: 42\n",
      "col_name: income before: 4 after: 4\n"
     ]
    }
   ],
   "source": [
    "# check before and after by comparing the unique values\n",
    "for i in before.keys():\n",
    "    print(f\"col_name: {i} before: {len(before[i])} after: {len(after[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c7f84f38b95c1",
   "metadata": {},
   "source": [
    "## Handling binary data\n",
    "\n",
    "male is 0 \n",
    "female is 1\n",
    "\n",
    "income less then 50k is 0\n",
    "income greater then 50k is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a78f280e58fb62e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.586514Z",
     "start_time": "2024-12-04T03:15:19.559687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/45/b_y3zsxs1g35byl6x6d4f9hw0000gn/T/ipykernel_10647/1168086075.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['sex'] = data['sex'].replace(sex_map)\n",
      "/var/folders/45/b_y3zsxs1g35byl6x6d4f9hw0000gn/T/ipykernel_10647/1168086075.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['income'] = data['income'].replace(income_map)\n"
     ]
    }
   ],
   "source": [
    "sex_map = {\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "}\n",
    "\n",
    "income_map = {\n",
    "    '<=50K': 0,\n",
    "    '>50K': 1,\n",
    "    '<=50K.': 0,\n",
    "    '>50K.': 1\n",
    "}\n",
    "\n",
    "# replace the values in the column\n",
    "data['sex'] = data['sex'].replace(sex_map)\n",
    "data['income'] = data['income'].replace(income_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e7d7712fa7cd030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.613641Z",
     "start_time": "2024-12-04T03:15:19.605118Z"
    }
   },
   "outputs": [],
   "source": [
    "continues_colname = ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#normalize the continues data\n",
    "scaler = StandardScaler()\n",
    "data[continues_colname] = scaler.fit_transform(data[continues_colname])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8299c34",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d91c1e4a206fa9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.644629Z",
     "start_time": "2024-12-04T03:15:19.634968Z"
    }
   },
   "outputs": [],
   "source": [
    "#split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=['income'])\n",
    "y = data['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26d517e34ae490b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:15:19.971384Z",
     "start_time": "2024-12-04T03:15:19.709835Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the system path\n",
    "src_path = Path('./src')  # Path to the src directory relative to your notebook\n",
    "sys.path.append(str(src_path.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ad64345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Epoch 0: Train Loss = 30.3506, Val Loss = 7.5892\n",
      "Epoch 50: Train Loss = 24.0858, Val Loss = 6.0481\n",
      "Epoch 100: Train Loss = 17.8211, Val Loss = 4.5070\n",
      "Epoch 150: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 200: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 250: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 300: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 350: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 400: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 450: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Epoch 499: Train Loss = 14.6460, Val Loss = 3.7260\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from model import svm\n",
    "import importlib\n",
    "importlib.reload(svm)\n",
    "\n",
    "from model.svm import svm_\n",
    "\n",
    "C = 0.001\n",
    "learning_rate = 0.0005\n",
    "epoch = 500\n",
    "\n",
    "\n",
    "my_svm = svm_(learning_rate=learning_rate,epoch=epoch,C_value=C,X=X_train,Y=y_train)\n",
    "# X_train = X_train.to_numpy()\n",
    "# y_train = y_train.to_numpy().reshape(-1, 1)\n",
    "\n",
    "# train model\n",
    "# ensuring y is in the set {-1, 1}\n",
    "y_train_preprocessed = 2 * y_train -1\n",
    "print(\"Training SVM...\")\n",
    "training_losses, validation_losses = my_svm.train(X_train, y_train_preprocessed)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ea51a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVM...\n",
      "Accuracy on test dataset: 0.752755905511811\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "print(\"Evaluating SVM...\")\n",
    "y_test_preprocessed = 2 * y_test -1\n",
    "my_svm.evaluate(X_test,y_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe2de35bb58612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:16:10.247863Z",
     "start_time": "2024-12-04T03:16:09.953989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1: train Loss: 0.6931471805599467 validation Loss: 0.6931471805599467\n",
      "Epoch: 101: train Loss: 0.5447578604105975 validation Loss: 0.5447578604105975\n",
      "Epoch: 201: train Loss: 0.5322006691883816 validation Loss: 0.5322006691883816\n",
      "Epoch: 301: train Loss: 0.5218408967641895 validation Loss: 0.5218408967641895\n",
      "Epoch: 401: train Loss: 0.5130994705150276 validation Loss: 0.5130994705150276\n",
      "Epoch: 501: train Loss: 0.5056013709343011 validation Loss: 0.5056013709343011\n",
      "Epoch: 601: train Loss: 0.4990898404898213 validation Loss: 0.4990898404898213\n",
      "Epoch: 701: train Loss: 0.4933802551194293 validation Loss: 0.4933802551194293\n",
      "Epoch: 801: train Loss: 0.48833452691695667 validation Loss: 0.48833452691695667\n",
      "Epoch: 901: train Loss: 0.48384618133861507 validation Loss: 0.48384618133861507\n",
      "Epoch: 1001: train Loss: 0.4798311686951479 validation Loss: 0.4798311686951479\n",
      "Epoch: 1101: train Loss: 0.47622190498047806 validation Loss: 0.47622190498047806\n",
      "Epoch: 1201: train Loss: 0.4729632294373842 validation Loss: 0.4729632294373842\n",
      "Epoch: 1301: train Loss: 0.4700095594803882 validation Loss: 0.4700095594803882\n",
      "Epoch: 1401: train Loss: 0.4673228284270511 validation Loss: 0.4673228284270511\n",
      "Train end\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Regularization\n",
    "from model import LogisticRegression\n",
    "import importlib\n",
    "importlib.reload(LogisticRegression)\n",
    "\n",
    "from model.LogisticRegression import LogisticRegression_\n",
    "\n",
    "\n",
    "lr_learning_rate = 0.001\n",
    "lr_epoch = 1500\n",
    "c = 0.001\n",
    "\n",
    "lr = LogisticRegression_(c,lr_learning_rate, lr_epoch, X_train, y_train)\n",
    "\n",
    "print(\"Training Logistic Regression Model\")\n",
    "lr.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f448b98870ece5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression ...\n",
      "Accuracy: 0.7618897637795276\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating LogisticRegression ...\")\n",
    "lr.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 76,
=======
   "execution_count": 71,
>>>>>>> 7c6928b08425774829653720e4579a80eca2d340
   "id": "ae7c6bf688b403d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T03:16:49.781779Z",
     "start_time": "2024-12-04T03:16:47.163367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Training Random Forest Classifier...\n",
      "fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ended\n",
      "aggregated predictions for  0  samples.\n",
      "aggregated predictions for  1000  samples.\n",
      "aggregated predictions for  2000  samples.\n",
      "aggregated predictions for  3000  samples.\n",
      "aggregated predictions for  4000  samples.\n",
      "aggregated predictions for  5000  samples.\n",
      "aggregated predictions for  6000  samples.\n",
      "aggregated predictions for  7000  samples.\n",
      "aggregated predictions for  8000  samples.\n",
      "aggregated predictions for  9000  samples.\n",
<<<<<<< HEAD
      "Accuracy: 0.8221522309711287\n",
      "Cross Entropy Loss: 6.410283342904405\n"
=======
      "Accuracy: 0.8041994750656168\n",
      "Cross Entropy Loss: 5.851749554569989\n"
>>>>>>> 7c6928b08425774829653720e4579a80eca2d340
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Random Forests\n",
    "\n",
    "from model.random_forest import random_forest\n",
    "\n",
<<<<<<< HEAD
    "rf = random_forest(forest_size=100, max_tree_depth=2)\n",
    "\n",
    "rf.fit(X_train.values, y_train) \n",
=======
    "rf = random_forest(forest_size=100)\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf.fit(X_train.values, y_train)\n",
    "print(\"Training ended\")\n",
>>>>>>> 7c6928b08425774829653720e4579a80eca2d340
    "\n",
    "y_pred, y_pred_probabilities = rf.predict(X_test.values)\n",
    "accuracy_score, entropy_loss = rf.evaluate(y_test_preprocessed, y_pred, y_pred_probabilities)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score}\")\n",
    "print(f\"Cross Entropy Loss: {entropy_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
